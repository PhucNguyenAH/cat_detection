{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-11-01T07:58:17.633628Z","iopub.status.busy":"2021-11-01T07:58:17.633302Z","iopub.status.idle":"2021-11-01T07:58:26.090001Z","shell.execute_reply":"2021-11-01T07:58:26.088945Z","shell.execute_reply.started":"2021-11-01T07:58:17.633542Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-01-07 12:12:28.788974: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-07 12:12:30.204888: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-12.0/lib64:/usr/local/cuda/lib64:/usr/local/cuda-11.8/lib64:/usr/local/cuda-11.8/extras/CUPTI/lib64:/usr/local/cuda-12.0/extras/CUPTI/lib64\n","2023-01-07 12:12:30.205114: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-12.0/lib64:/usr/local/cuda/lib64:/usr/local/cuda-11.8/lib64:/usr/local/cuda-11.8/extras/CUPTI/lib64:/usr/local/cuda-12.0/extras/CUPTI/lib64\n","2023-01-07 12:12:30.205125: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","2023-01-07 12:12:31.486551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-07 12:12:31.736537: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-07 12:12:31.736798: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-07 12:12:31.737752: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-07 12:12:31.738297: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-07 12:12:31.738475: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-07 12:12:31.738609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-07 12:12:32.500199: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-07 12:12:32.500487: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-07 12:12:32.500680: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-07 12:12:32.500835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6336 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 12s 0us/step\n","Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 0\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}],"source":["from keras.applications.vgg16 import VGG16\n","\n","# load model\n","vgg = VGG16(weights=\"imagenet\",include_top=False,input_shape=(224,224,3))\n","# freeze\n","vgg.trainable = False\n","# summarize the model\n","vgg.summary()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-11-01T08:31:31.661287Z","iopub.status.busy":"2021-11-01T08:31:31.660937Z","iopub.status.idle":"2021-11-01T08:31:31.691656Z","shell.execute_reply":"2021-11-01T08:31:31.690399Z","shell.execute_reply.started":"2021-11-01T08:31:31.661253Z"},"trusted":true},"outputs":[],"source":["import enum\n","import numpy as np\n","import cv2 \n","from matplotlib import pyplot as plt\n","from keras.layers import *\n","import os\n","\n","class CatFeatures(enum.Enum):\n","    # below are the cat facial features (⊙o⊙)\n","    # eyes\n","    LEFT_EYE = 0\n","    RIGHT_EYE = 1\n","    # mouth\n","    MOUTH = 2\n","    # left ear\n","    LEFT_EAR_1 = 3\n","    LEFT_EAR_2 = 4\n","    LEFT_EAR_3 = 5\n","    # right ear\n","    RIGHT_EAR_1 = 6\n","    RIGHT_EAR_2 = 7\n","    RIGHT_EAR_3 = 8\n","    \n","def load_image(path):\n","    img = cv2.imread(path)\n","    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","    labels = load_labels(path)[1:]\n","\n","    w,h = img.shape[:2]\n","    \n","    return img, labels , w , h\n","    \n","def load_labels(path):\n","    path = path + \".cat\"\n","    \n","    with open(path,'r') as f:\n","        coordinates = f.readline()\n","        coordinates = str(coordinates).split(' ')[:-1]\n","    \n","    return list(map(int,coordinates))\n","\n","def map_labels(labels):\n","    x = labels[0:18:2]\n","    y = labels[1:18:2]\n","    \n","    features ={\n","        CatFeatures.LEFT_EYE : (),\n","        CatFeatures.RIGHT_EYE : (),\n","        CatFeatures.MOUTH : (),\n","        CatFeatures.LEFT_EAR_1 : (),\n","        CatFeatures.LEFT_EAR_2 : (),\n","        CatFeatures.LEFT_EAR_3 : (),\n","        CatFeatures.RIGHT_EAR_1 : (),\n","        CatFeatures.RIGHT_EAR_2 : (),\n","        CatFeatures.RIGHT_EAR_3 : (),\n","              }\n","    for key,xpoint,ypoint in zip(features.keys(),x,y):\n","        features[key] = (xpoint,ypoint)\n","    \n","    return features\n","    \n","def init_dataset(path,preprocess=False):\n","    root_path = path\n","    images = []\n","    labels = []\n","    \n","    for root,_,files in os.walk(root_path):\n","        for file in files:\n","            if file.endswith('.jpg'):\n","                x,y,w,h = load_image(os.path.join(root,file))\n","                \n","                if preprocess:\n","                    # preprocess data here !\n","                    x = preprocess_image(x)\n","                    # preprocess labels\n","                    y = preprocess_labels(y,w,h)\n","                images.append(x)\n","                labels.append(y)\n","    \n","    images = np.asarray(images)\n","    labels = np.asarray(labels)\n","    \n","    return images, labels.reshape(-1,18)\n","\n","def preprocess_image(image):\n","    x = image / 255.0\n","    x = cv2.resize(x,(224,224))\n","    x = np.asarray(x).astype('float32')\n","    return x\n","\n","def preprocess_labels(labels,width,height):\n","    y = labels\n","    y[0:18:2] = list(map(lambda point: point / width, y[0:18:2])) # x\n","    y[1:18:2] = list(map(lambda point: point / height, y[1:18:2])) # y\n","    return y\n","\n","def create_dense_layer(nodes):\n","    layer = [\n","        Dense(nodes,activation='relu'),\n","        BatchNormalization(),\n","        #Dropout(0.2)\n","    ]\n","    return layer\n","\n","def create_regression_net():\n","    start_nodes = 256\n","    nb_layers = 4\n","    \n","    regression = Sequential()\n","    regression.add(BatchNormalization())\n","    \n","    for i in range(nb_layers):\n","        nodes = start_nodes / 2\n","        \n","        layers = create_dense_layer(nodes)\n","        \n","        for l in layers:\n","            regression.add(l)\n","        \n","        start_nodes = nodes\n","        \n","    regression.add(Dense(18,activation='sigmoid'))\n","    \n","    return regression\n","\n","def build_network(feature_extractor_net):\n","    model = Sequential()\n","    model.add(feature_extractor_net)\n","    model.add(Flatten())\n","    model.add(create_regression_net())\n","\n","    return model\n","\n","def decode_labels(labels,width,heigth):\n","    labels[0:18:2] = labels[0:18:2] * width\n","    labels[1:18:2] = labels[1:18:2] * heigth\n","    return labels\n","\n","def predict_image(path, model):\n","    img = cv2.imread(path)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    (w, h) = img.shape[:2]\n","    \n","    # predictions\n","    image_preprocessed = preprocess_image(img)\n","    y = model.predict(np.expand_dims(image_preprocessed, axis=0)).flatten()\n","    y = decode_labels(y, w, h)\n","    show_cat(img,y)\n","\n","def show_cat(image,labels):\n","    features = map_labels(labels)\n","\n","    plt.imshow(image)\n","    #plt.scatter(labels[0:18:2],labels[1:18:2],c='r',)\n","    \n","    \n","    x,y = [],[]\n","    points = [CatFeatures.LEFT_EAR_1,\n","              CatFeatures.LEFT_EAR_2,\n","              CatFeatures.LEFT_EAR_3,\n","              CatFeatures.RIGHT_EAR_1,\n","              CatFeatures.RIGHT_EAR_2,\n","              CatFeatures.RIGHT_EAR_3,\n","              CatFeatures.MOUTH,\n","              CatFeatures.LEFT_EAR_1,\n","             ]\n","    \n","    for p in points:\n","        x.append(features[p][0])\n","        y.append(features[p][1])\n","    \n","    lines = plt.plot(x,y,marker='*')\n","    plt.setp(lines, color='c',)\n","    plt.show()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-11-01T07:58:28.449872Z","iopub.status.busy":"2021-11-01T07:58:28.449583Z","iopub.status.idle":"2021-11-01T08:00:12.920856Z","shell.execute_reply":"2021-11-01T08:00:12.919685Z","shell.execute_reply.started":"2021-11-01T07:58:28.449839Z"},"trusted":true},"outputs":[],"source":["# preprocess data\n","train_paths = ['../archive/CAT_00/','../archive/CAT_01/']\n","\n","x_train,y_train = np.empty((0,224,224,3)), np.empty((0,18))\n","\n","for path in train_paths:\n","    (x,y) = init_dataset(path,preprocess=True)\n","    x_train = np.vstack((x_train,x))\n","    y_train = np.vstack((y_train,y))\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-11-01T08:00:12.92313Z","iopub.status.busy":"2021-11-01T08:00:12.922724Z","iopub.status.idle":"2021-11-01T08:00:16.343616Z","shell.execute_reply":"2021-11-01T08:00:16.342417Z","shell.execute_reply.started":"2021-11-01T08:00:12.923066Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, y_train, y_test = train_test_split(x_train,y_train, test_size=0.33, random_state=42)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-11-01T08:00:16.345832Z","iopub.status.busy":"2021-11-01T08:00:16.345556Z","iopub.status.idle":"2021-11-01T08:00:16.950276Z","shell.execute_reply":"2021-11-01T08:00:16.949041Z","shell.execute_reply.started":"2021-11-01T08:00:16.345793Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," sequential_1 (Sequential)   (None, 18)                3323874   \n","                                                                 \n","=================================================================\n","Total params: 18,038,562\n","Trainable params: 3,273,218\n","Non-trainable params: 14,765,344\n","_________________________________________________________________\n"]}],"source":["from keras.models import Sequential, Model\n","from tensorflow.keras.optimizers import Adam\n","\n","model = build_network(vgg)\n","    \n","model.summary()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2021-11-01T08:00:16.952682Z","iopub.status.busy":"2021-11-01T08:00:16.952457Z","iopub.status.idle":"2021-11-01T08:00:16.970808Z","shell.execute_reply":"2021-11-01T08:00:16.969748Z","shell.execute_reply.started":"2021-11-01T08:00:16.952654Z"},"trusted":true},"outputs":[],"source":["model.compile(optimizer=Adam(learning_rate=0.001),loss='mse',metrics=['accuracy'])"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2021-11-01T08:00:16.973307Z","iopub.status.busy":"2021-11-01T08:00:16.972957Z","iopub.status.idle":"2021-11-01T08:18:43.995139Z","shell.execute_reply":"2021-11-01T08:18:43.994018Z","shell.execute_reply.started":"2021-11-01T08:00:16.97325Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-01-07 12:16:04.721359: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1340903424 exceeds 10% of free system memory.\n","2023-01-07 12:16:06.193304: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1340903424 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/150\n"]},{"name":"stderr","output_type":"stream","text":["2023-01-07 12:16:11.620615: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8700\n","2023-01-07 12:16:13.001707: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n","2023-01-07 12:16:15.538128: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x56553a09ba20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-01-07 12:16:15.538153: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 2070 with Max-Q Design, Compute Capability 7.5\n","2023-01-07 12:16:15.568752: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2023-01-07 12:16:15.802244: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n","2023-01-07 12:16:15.850456: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["70/70 [==============================] - ETA: 0s - loss: 0.0899 - accuracy: 0.0337"]},{"name":"stderr","output_type":"stream","text":["2023-01-07 12:16:28.002633: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 660516864 exceeds 10% of free system memory.\n","2023-01-07 12:16:28.749484: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 660516864 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["70/70 [==============================] - 27s 236ms/step - loss: 0.0899 - accuracy: 0.0337 - val_loss: 0.0677 - val_accuracy: 0.0602\n","Epoch 2/150\n","70/70 [==============================] - 11s 158ms/step - loss: 0.0549 - accuracy: 0.0552 - val_loss: 0.0425 - val_accuracy: 0.0930\n","Epoch 3/150\n","70/70 [==============================] - 11s 159ms/step - loss: 0.0349 - accuracy: 0.1419 - val_loss: 0.0278 - val_accuracy: 0.3108\n","Epoch 4/150\n","70/70 [==============================] - 11s 160ms/step - loss: 0.0215 - accuracy: 0.2919 - val_loss: 0.0209 - val_accuracy: 0.4403\n","Epoch 5/150\n","70/70 [==============================] - 43s 626ms/step - loss: 0.0140 - accuracy: 0.4086 - val_loss: 0.0178 - val_accuracy: 0.4722\n","Epoch 6/150\n","70/70 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.4589"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mCanceled future for execute_request message before replies were done"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=150,batch_size=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-01T08:21:02.996055Z","iopub.status.busy":"2021-11-01T08:21:02.992019Z","iopub.status.idle":"2021-11-01T08:21:04.012366Z","shell.execute_reply":"2021-11-01T08:21:04.011398Z","shell.execute_reply.started":"2021-11-01T08:21:02.996021Z"},"trusted":true},"outputs":[],"source":["img,l,w,h = load_image('../input/cat-dataset/CAT_05/00001100_003.jpg')\n","\n","# ground truth\n","figure = plt.subplot(1,2,1)\n","figure.set_title('Ground Truth')\n","plt.axis('off')\n","plt.imshow(img)\n","plt.scatter(l[0:18:2],l[1:18:2])\n","\n","# predictions\n","\n","image = preprocess_image(img)\n","y = model.predict(np.expand_dims(image,axis=0)).flatten()\n","y = decode_labels(y,w,h)\n","\n","figure = plt.subplot(1,2,2)\n","figure.set_title('Predicted')\n","plt.axis('off')\n","plt.imshow(img)\n","plt.scatter(y[0:18:2],y[1:18:2])\n","\n","# def test_image(path):\n","#     img,l,w,h = load_image('../input/cat-dataset/CAT_01/00000100_003.jpg')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-01T08:35:26.510223Z","iopub.status.busy":"2021-11-01T08:35:26.509838Z","iopub.status.idle":"2021-11-01T08:35:26.844038Z","shell.execute_reply":"2021-11-01T08:35:26.842986Z","shell.execute_reply.started":"2021-11-01T08:35:26.510193Z"},"trusted":true},"outputs":[],"source":["model.save('pred.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-01T08:31:35.310214Z","iopub.status.busy":"2021-11-01T08:31:35.309406Z","iopub.status.idle":"2021-11-01T08:31:35.734926Z","shell.execute_reply":"2021-11-01T08:31:35.733994Z","shell.execute_reply.started":"2021-11-01T08:31:35.310141Z"},"trusted":true},"outputs":[],"source":["predict_image('../input/cat-dataset/CAT_00/00000006_006.jpg',model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-01T08:33:27.210757Z","iopub.status.busy":"2021-11-01T08:33:27.210463Z","iopub.status.idle":"2021-11-01T08:33:27.54658Z","shell.execute_reply":"2021-11-01T08:33:27.54558Z","shell.execute_reply.started":"2021-11-01T08:33:27.210713Z"},"trusted":true},"outputs":[],"source":["predict_image('../input/cat-dataset/CAT_00/00000011_014.jpg',model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"wowAI","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:26:04) [GCC 10.4.0]"},"vscode":{"interpreter":{"hash":"c69c34fcec5bc1074ae45c9e9b80001e096797f72ef5a29b0d6ab4c04a8857e6"}}},"nbformat":4,"nbformat_minor":4}
